{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaHaaT/cifar-10/blob/main/cifar_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BkHlVrAhEaX"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnjuoVLihEab"
      },
      "outputs": [],
      "source": [
        "# GPUが使えるかの確認\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGH2j9i-hEac"
      },
      "source": [
        "### CIFAR-10のデータセットをダウンロードする準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7ZxdAERhEad"
      },
      "outputs": [],
      "source": [
        "# 画像データの変換&データ拡張\n",
        "# 訓練用・検証用\n",
        "trainset_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # 画像データをTensor型に変換 & [0,255] → [0,1]の正規化\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # RGB値の平均と標準偏差の値を予め設定して標準化 今回は[0,1] → [-1,1]のように変換している。\n",
        "    transforms.RandomHorizontalFlip(p=0.4), # データ拡張\n",
        "    transforms.RandomVerticalFlip(p=0.4), #データ拡張\n",
        "    transforms.RandomRotation(degrees=[-45, 45]) # データ拡張\n",
        "])\n",
        "\n",
        "\"\"\"\n",
        "CIFAR-10の元々の画像データはPIL形式\n",
        "Tensor型への変換では, (縦, 横, 色チャネル数)を(色チャネル数, 縦, 横)に変換している\n",
        "※ PIL形式のサイズは (縦, 横)\n",
        "\"\"\"\n",
        "# テスト用 (テスト用にはデータ拡張を行わない)\n",
        "testset_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1nGDt5dhEad"
      },
      "source": [
        "### CIFAR-10のDatasetをダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50WJ_n-7hEae"
      },
      "outputs": [],
      "source": [
        "# 訓練用と検証用データの準備\n",
        "train_validation_dataset = CIFAR10(root='./data', train=True, download=True, transform=trainset_transform)\n",
        "\n",
        "# テスト用データの準備\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=testset_transform)\n",
        "\n",
        "#CIFAR-10のデータセットに含まれる対象クラス (10クラス)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CvZ0qcFhEae"
      },
      "source": [
        "### Datasetの数の確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqCoLIABhEae"
      },
      "outputs": [],
      "source": [
        "print('訓練用データの数 + 検証用データの数: ', len(train_validation_dataset))\n",
        "print('テスト用データの数: ', len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aed2GQ0mhEaf"
      },
      "source": [
        "### train_validation_datasetを訓練用と検証用に分割"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkM_pAb_hEaf"
      },
      "outputs": [],
      "source": [
        "# train_validation_datasetを訓練用と検証用に分割 (少し時間が掛かる　約30秒～1分過ぎぐらい)\n",
        "train_dataset, validation_dataset = train_test_split(train_validation_dataset, test_size=0.2, shuffle=True)\n",
        "print('訓練用データの数: ', len(train_dataset))\n",
        "print('検証用データの数: ', len(validation_dataset))\n",
        "print('テスト用データの数: ', len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJksKN9EhEaf"
      },
      "source": [
        "### Dataloaderの作成 (ミニバッチ学習の準備)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xIZBWCwhEag"
      },
      "outputs": [],
      "source": [
        "# バッチサイズの設定 ※ 1イテレーションごとに流す画像データの数\n",
        "batch_size = 32\n",
        "\n",
        "# Dataloaderの作成\n",
        "# 画像データをミニバッチ(データの小さな集まり)に分けて学習させる準備。今回はデータを32個の塊としている (batch_size = 32)。\n",
        "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "validationloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "\"\"\"\n",
        "shuffle=Trueにすることでエポックが回るごとにミニバッチの中身がランダムに入れ替わる。\n",
        "num_workersはミニバッチを作成する際の並列実行数\n",
        "\"\"\"\n",
        "\n",
        "# 辞書型にDataloaderを格納\n",
        "dataloader_dict = {'train': trainloader, 'validation': validationloader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DySUTf2OhEag"
      },
      "source": [
        "### 1つのミニバッチの中身を確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u3Xv8RdhEag"
      },
      "outputs": [],
      "source": [
        "# 訓練用のDataloaderからミニバッチを1つ抽出する\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XoziO20hEag"
      },
      "outputs": [],
      "source": [
        "# 1つのミニバッチから画像情報を表示する\n",
        "print('[画像データの数, 色チャネル数(RGB), 縦, 横]: ', images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49Ia4gVshEag"
      },
      "outputs": [],
      "source": [
        "# 1つのミニバッチから正解ラベルを表示する\n",
        "print('32個の正解ラベルを表示: ', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzZKQ5UKhEag"
      },
      "source": [
        "### 画像データと正解ラベルの確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6zl_KHwhEag"
      },
      "outputs": [],
      "source": [
        "# 画像と正解ラベルを表示\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 # 最小値を0, 最大値を1にする\n",
        "    img = img.numpy() # tensor配列をndarray配列に変換する\n",
        "    img = np.transpose(img, (1, 2, 0)) # (色チャネル数, 縦, 横) → (縦, 横, 色チャネル数)に変換する\n",
        "    plt.imshow(img)\n",
        "\n",
        "# 5つの画像をランダムに表示\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "for i in range(5):\n",
        "    n = np.random.choice(len(images))\n",
        "    ax = fig.add_subplot(1, 5, i+1)\n",
        "    imshow(images[n])\n",
        "    ax.set_title(classes[labels[n]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0eHylbRhEag"
      },
      "source": [
        "### CNNのモデルを定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9jE-4z6hEag"
      },
      "outputs": [],
      "source": [
        "# CNNのモデル構造を定義する\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, class_num):\n",
        "        super(CNN, self).__init__()\n",
        "        # 畳み込み層\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, padding=2) # 3チャネル(RGB)の画像データに対して64個のカーネルを用意する → 64個の特徴マップ(64個のチャネルを持つ画像データ)が出力される。\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1) # 64個のチャネルを持つ画像データに対して128個のカーネルを用意する → 128個の特徴マップ(128個のチャネルを持つ画像データ)が出力される。\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1) # 上と同じ流れ\n",
        "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1) # 上と同じ流れ\n",
        "\n",
        "        # 全結合層\n",
        "        conv4_output_size = 2 * 2 * 512 # 全結合層に入る前：2x2の特徴マップが512個出力される\n",
        "        self.fc1 = nn.Linear(in_features=conv4_output_size, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=class_num) # 最後の出力層のノードの数はクラス数と同じ10個\n",
        "\n",
        "        # 活性化関数\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        # プーリング層\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = self.pool(self.relu(self.conv4(x)))\n",
        "        x = torch.flatten(x, 1)  # 次元を1次元に落とす\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x) # 10個の確率を出力する\n",
        "        return x\n",
        "\n",
        "\"\"\"\n",
        "classとは言わば設計図のようなもので, 設計図を定義した後にそこから実体(インスタンス)を作成する。\n",
        "イメージ: 動物という設計図を定義したら, イヌ, ネコ, 人間という実体を作成することができる。\n",
        "\"\"\"\n",
        "\n",
        "model = CNN(class_num=len(classes)) # CNNという設計図を作成して, modelという実体(インスタンス)を作成した。\n",
        "model.to(device) # modelをGPU上へ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOEPjFAwhEah"
      },
      "source": [
        "### 学習に使う損失関数と最適化アルゴリズムを定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpk6oek_hEah"
      },
      "outputs": [],
      "source": [
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss() # 交差エントロピー誤差 (多クラス分類によく用いられる)\n",
        "\n",
        "\"\"\"\n",
        "2クラス分類 → バイナリ交差エントロピー誤差\n",
        "多クラス分類 → 交差エントロピー誤差\n",
        "\"\"\"\n",
        "\n",
        "# 最適化アルゴリズム(勾配降下法)の定義\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.0001) # Adamというアルゴリズムを用いて勾配降下法を行う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRoO70yHhEah"
      },
      "source": [
        "### 学習の開始"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_O4Llf3hEah"
      },
      "outputs": [],
      "source": [
        "epoch_num = 20 # エポックの数 ※ 1epoch = 全データセットを1回使うこと, 10epoch = 10回全データセットを使ったことに相当する\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "validation_losses = []\n",
        "validation_accs = []\n",
        "\n",
        "# 学習 (Epoch=20で約3分掛かる)\n",
        "for epoch in range(epoch_num):\n",
        "    print('Epoch: {}/{}'.format(epoch+1, epoch_num))\n",
        "    for phase in ['train', 'validation']:\n",
        "        if phase == 'train':\n",
        "            model.train() # モデルを訓練モードに設定\n",
        "        else:\n",
        "            model.eval() # モデルを検証モードに設定\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "\n",
        "        for imgs, labels in dataloader_dict[phase]:\n",
        "            imgs = imgs.to(device) # GPU上へ\n",
        "            labels = labels.to(device) # GPU上へ\n",
        "            one_hot_labels = F.one_hot(labels, num_classes=len(classes)).float() # One-hot vectorに変換 例) ラベル7 → (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)\n",
        "            optimizer.zero_grad() # 重みパラメータの勾配を0に初期化\n",
        "            outputs = model(imgs) # モデルの学習結果を出力する\n",
        "            loss = criterion(outputs, one_hot_labels) # 正解値と予測値の損失差を計算する\n",
        "\n",
        "            # 訓練時だけに適用\n",
        "            if phase == 'train':\n",
        "                loss.backward() # 誤差逆伝播を行い, 重みパラメータの勾配を求める\n",
        "                optimizer.step() # 最適化アルゴリズムを用いて重みパラメータを更新する\n",
        "\n",
        "            running_loss += loss.item() # 1イテレーションごとに損失差の値が追加されていく\n",
        "            predicted_labels = torch.argmax(outputs, dim=1) # 一番大きい値を示したインデックス番号を抽出する\n",
        "            running_acc += torch.mean(predicted_labels.eq(labels).float()) # 1イテレーションごとの正解率が追加されていく\n",
        "\n",
        "        running_loss /= len(dataloader_dict[phase]) # イテレーションの数で割ることで, 平均損失差を計算して, 1epoch分の損失差を出力\n",
        "        running_acc /= len(dataloader_dict[phase]) # イテレーションの数で割ることで, 平均正解率を計算して, 1epoch分の正解率を出力\n",
        "        running_acc = running_acc.item()\n",
        "\n",
        "        if phase == 'train':\n",
        "            train_losses.append(running_loss)\n",
        "            train_accs.append(running_acc)\n",
        "            print('train loss: {:.3f}, train acc: {:.3f}'.format(running_loss, running_acc))\n",
        "\n",
        "        else:\n",
        "            validation_losses.append(running_loss)\n",
        "            validation_accs.append(running_acc)\n",
        "            print('validation loss: {:.3f}, validation acc: {:.3f}'.format(running_loss, running_acc))\n",
        "    print('------------------------')\n",
        "\n",
        "print('学習が終了しました。')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTRMvSebhEah"
      },
      "source": [
        "### 学習中の損失差と正解率の推移"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhnMTd8ShEah"
      },
      "outputs": [],
      "source": [
        "# 損失差の推移をプロット\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_losses, label='train', linewidth=2, color='coral')\n",
        "plt.plot(validation_losses, label='validation', linewidth=2, color='dodgerblue')\n",
        "plt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
        "plt.title('Loss', fontsize=20)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPKkKhIghEah"
      },
      "outputs": [],
      "source": [
        "# 正解率の推移をプロット\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_accs, label='train', linewidth=2, color='coral')\n",
        "plt.plot(validation_accs, label='validation', linewidth=2, color='dodgerblue')\n",
        "plt.gca().xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
        "plt.title('Accuracy', fontsize=20)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz5p-fPShEai"
      },
      "source": [
        "### 学習後のモデルパラメータを保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRsozLm_hEai"
      },
      "outputs": [],
      "source": [
        "# 学習したモデルパラメータの保存\n",
        "SAVED_PATH = './model_epoch_{}.pth'.format(epoch_num)\n",
        "if not os.path.isfile(SAVED_PATH):\n",
        "    torch.save(model.state_dict(), SAVED_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7P9aKoThEai"
      },
      "source": [
        "### テスト用CNNモデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iKkb50khEai"
      },
      "outputs": [],
      "source": [
        "test_model = CNN(class_num=len(classes))\n",
        "test_model.load_state_dict(torch.load(SAVED_PATH)) # 保存された重みパラメータを使う\n",
        "test_model.eval() # 推論モードに切り替える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-Iebw9chEai"
      },
      "source": [
        "### テスト用のDataloaderの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEKMqX5nhEai"
      },
      "outputs": [],
      "source": [
        "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bk5m-YFhEai"
      },
      "source": [
        "### 推論の開始"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHdUO9IghEai"
      },
      "outputs": [],
      "source": [
        "# テスト用のDataloaderからミニバッチを1つ抽出する\n",
        "dataiter = iter(testloader)\n",
        "test_images, test_labels = next(dataiter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JJ6S5AAhEai"
      },
      "outputs": [],
      "source": [
        "# 推論\n",
        "with torch.no_grad(): # 勾配計算は行わないように設定\n",
        "    test_images.to(device)\n",
        "    outputs = test_model(test_images)\n",
        "    predicted_labels = torch.argmax(outputs, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9Xxg_eDhEai"
      },
      "source": [
        "### 正解クラスと予測クラスの比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGf1m-RbhEai"
      },
      "outputs": [],
      "source": [
        "# ランダムな画像を5つ表示\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "for i in range(5):\n",
        "    n = np.random.choice(len(test_images))\n",
        "    ax = fig.add_subplot(1, 5, i+1)\n",
        "    imshow(test_images[n])\n",
        "    correct_class = classes[test_labels[n]]\n",
        "    predicted_class = classes[predicted_labels[n]]\n",
        "    if correct_class == predicted_class:\n",
        "        ax.set_xlabel('GOOD')\n",
        "        ax.xaxis.label.set_color('red')\n",
        "    else:\n",
        "        ax.set_xlabel('BAD')\n",
        "    ax.set_title('c = {}, p = {}'.format(correct_class, predicted_class)) # 正解クラスと予測クラスを見比べる\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cokRu7UThEai"
      },
      "source": [
        "### Heatmapで表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ7-Tat-hEao"
      },
      "outputs": [],
      "source": [
        "testloader_2 = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False, num_workers=2)\n",
        "dataiter = iter(testloader_2)\n",
        "test_images, test_labels = next(dataiter)\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# 約1分掛かる\n",
        "with torch.no_grad():\n",
        "    test_images.to(device)\n",
        "    outputs = test_model(test_images)\n",
        "    predicted_labels = torch.argmax(outputs, dim=1)\n",
        "    for test_label, predicted_label in zip(test_labels, predicted_labels):\n",
        "            if test_label == predicted_label:\n",
        "                correct_pred[classes[test_label]] += 1\n",
        "            total_pred[classes[test_label]] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCKZvFqNhEao"
      },
      "outputs": [],
      "source": [
        "print('クラスごとの正解率')\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'{classname:5s} is {accuracy:.1f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhVZxwbchEao"
      },
      "outputs": [],
      "source": [
        "# Heatmapの表示\n",
        "cm = confusion_matrix(predicted_labels, test_labels)\n",
        "cm = pd.DataFrame(data=cm, index=classes, columns=classes)\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(cm, square=True, cbar=True, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Correct class', fontsize=12)\n",
        "plt.ylabel('Predicted class', fontsize=12)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}